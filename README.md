
# Telecom X ‚Äì Parte 2: Predicci√≥n de Cancelaci√≥n (Churn)

## üìå Prop√≥sito del proyecto
Este proyecto tiene como objetivo construir un pipeline de Machine Learning para **predecir la cancelaci√≥n de clientes (churn)** en Telecom X, identificando los factores m√°s influyentes y proponiendo estrategias de retenci√≥n basadas en datos.

---

## üß† Objetivo principal
- Predecir qu√© clientes tienen mayor probabilidad de cancelar (churn).
- Evaluar al menos dos modelos de clasificaci√≥n.
- Interpretar variables relevantes (coeficientes / importancias).
- Proponer estrategias accionables de retenci√≥n.

---

## üìÇ Estructura del proyecto
- `TelecomX_Parte2_Churn.ipynb` ‚Üí Notebook principal con todo el pipeline (preprocesamiento, modelos, evaluaci√≥n e insights).
- `datos_tratados.csv` ‚Üí Dataset tratado de la Parte 1 (limpio y estandarizado).  
  > Nota: si no est√° en el repositorio, ver secci√≥n ‚ÄúDatos‚Äù.
- `README.md` ‚Üí Documentaci√≥n del proyecto.
- (Opcional) `figures/` ‚Üí Carpeta para guardar gr√°ficos exportados (boxplots, correlaci√≥n, etc.).

---

## üßπ Preparaci√≥n de datos
### Tipos de variables
- **Categ√≥ricas**: variables relacionadas con servicios, contrato, m√©todo de pago, etc.
- **Num√©ricas**: variables de antig√ºedad y cobros (por ejemplo: `tenure`, `MonthlyCharges`, `TotalCharges`).

### Etapas de preprocesamiento
1. **Limpieza**
   - Eliminaci√≥n de columnas irrelevantes como identificadores (`customerID`).
   - Manejo de nulos (eliminaci√≥n de filas sin etiqueta `churn_01`, si aplica).
2. **Codificaci√≥n**
   - Variables categ√≥ricas ‚Üí **One-Hot Encoding**.
3. **Estandarizaci√≥n / Normalizaci√≥n (seg√∫n modelo)**
   - Modelos sensibles a escala (Regresi√≥n Log√≠stica / SVM / KNN) ‚Üí **StandardScaler** en variables num√©ricas.
   - Modelos basados en √°rboles (Decision Tree / Random Forest) ‚Üí no requieren escalado.
4. **Separaci√≥n de datos**
   - Divisi√≥n en entrenamiento y prueba con `train_test_split` (80/20), usando `stratify=y` para mantener la proporci√≥n de churn.

---

## ü§ñ Modelizaci√≥n y justificaciones
Se entrenaron al menos dos modelos:

### 1) Regresi√≥n Log√≠stica (con estandarizaci√≥n)
- Justificaci√≥n: modelo sensible a escala; el escalado evita que variables con magnitudes grandes dominen el entrenamiento.
- Ventaja: interpretabilidad mediante coeficientes (qu√© variables aumentan/reducen churn).

### 2) Random Forest (sin estandarizaci√≥n)
- Justificaci√≥n: modelo basado en √°rboles; no depende de distancias ni escala.
- Ventaja: captura relaciones no lineales y ofrece importancia de variables.

> Nota: como el churn suele estar desbalanceado, se prioriza el an√°lisis con m√©tricas como Recall y F1, adem√°s de Accuracy.

---

## üìä EDA y principales insights
Ejemplos de an√°lisis exploratorio incluidos:
- **Matriz de correlaci√≥n** (variables num√©ricas vs churn).
- **Boxplots** para analizar:
  - `tenure` vs churn
  - `TotalCharges` vs churn
- Tendencia t√≠pica: churn m√°s alto en clientes con **tenure bajo** y/o **contratos mensuales (month-to-month)**.

---

## ‚úÖ Evaluaci√≥n de modelos
M√©tricas utilizadas:
- **Accuracy (Exactitud)**
- **Precision (Precisi√≥n)**
- **Recall**
- **F1-score**
- **Matriz de confusi√≥n**

Comparaci√≥n cr√≠tica:
- Se analiza cu√°l modelo ofrece mejor rendimiento seg√∫n el objetivo de negocio:
  - Mayor **Recall** si se busca detectar m√°s churners (retenci√≥n agresiva).
  - Mejor **F1** si se busca equilibrio entre capturar churn y reducir falsas alarmas.

---

## üéØ Estrategias de retenci√≥n propuestas
Basado en variables relevantes:
- Enfocar retenci√≥n en clientes con **tenure bajo** (onboarding 30‚Äì90 d√≠as).
- Incentivar migraci√≥n de **month-to-month** a contratos de 1‚Äì2 a√±os.
- Ofrecer bundles de valor: **TechSupport + OnlineSecurity**.
- Revisar segmentaci√≥n de precio para clientes con **MonthlyCharges altos**.
- Facilitar m√©todos de pago (incentivos para autopago).

---

## ‚ñ∂Ô∏è C√≥mo ejecutar el proyecto
### Requisitos
En Google Colab o entorno local, instalar librer√≠as principales:

```bash
pip install pandas numpy scikit-learn imbalanced-learn
